<!DOCTYPE html>
<html lang="en">
<meta charset="utf-8">
<title>DS-GA 1003: Machine Learning, Spring 2023</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<link rel="stylesheet" href="styles/style.css">
<link rel="stylesheet" media="only screen and (max-width: 770px)" href="styles/tablet-and-phone.css">
<link rel="stylesheet" media="only screen and (max-width: 420px)" href="styles/phone.css">
<link rel="icon" href="favicon.ico" type="image/vnd.microsoft.icon">
<link rel="canonical" href="https://davidrosenberg.github.io/ml2019">

<nav>
    <a href="#home">Home</a>
    <a href="#about">About</a>
    <a href="#resources">Resources</a>
    <a href="#lectures">Lectures</a>
    <a href="#assignments">Assignments</a>
    <a href="#people">People</a>
</nav>

<section id="home">
    <h1>
        Machine Learning
        <span class="course">
            DS-GA 1003 · Spring 2023 ·
            <a class="department" href="http://cds.nyu.edu/">NYU Center for Data Science</a>
        </span>
    </h1>

    <table id="course-info">
        <tr>
            <th rowspan="2">Instructors</th>
            <td>Mengye Ren<a class="icon email"
href="mailto:mengye@cs.nyu.edu"></a></td>
        </tr>

        <tr>
            <td>Ravid Shwartz-Ziv<a class="icon email" href="mailto:rs8020@nyu.edu"></a></td>
        </tr>

        <tr>
            <th>Lecture</th>
		        <td>Tuesday 4:55pm-6:35pm (GCASL C95)
                 <!-- - <a href="https://nyu.zoom.us/j/99547855896">Zoom Link</a> </td> -->
        </tr>

        <tr>
            <th rowspan="5">Lab</th>
			<td> Wednesday 4:55pm-5:45pm (GCASL C95)
             <!-- - <a href="https://nyu.zoom.us/j/99755110094">Zoom Link</a> <td> -->
        </tr>
    </table>

</section>
<section id="about">
    <h1>About This Course</h1>

    <div class="module">
        <p>This course covers a wide variety of introductory topics in machine learning and statistical modeling,
        including statistical learning theory, convex optimization, generative and discriminative models, kernel methods, boosting, latent variable models and so on.
        The primary goal is to provide students with the tools and principles needed to solve the data science problems found in practice.
        This course was designed as part of the core curriculum for the Center for Data Science's <a href="http://cds.nyu.edu/academics/ms-in-data-science/">Masters degree in Data Science</a>, and is intended as a continuation of DS-GA-1001 Intro to Data Science.
        This course also serves as a foundation on which more specialized courses and further independent study can build.
        Course syllabus can be found <a href="https://docs.google.com/document/d/1RWu_zPWXXrilQWYpIvpSih27jUVsy1vD8txWeKrR2Yg/edit?usp=sharing">here</a>.</p>
        </p>

        <p>For registration information, please contact <a href="mailto:tina.lam@nyu.edu">Tina Lam</a>.</p>
    </div>

    <section>
        <h1>Prerequisites</h1>
        <p>
        If you'd like to waive the prerequisites, please send an email to Mengye Ren (mengye@cs.nyu.edu), Ravid Shwartz-Ziv (rs8020@nyu.edu).
        Note that this course requires some basic understanding of machine learning (covered by DS-GA-1001).
        For each prerequisite, please clearly list which courses you've taken are equivalent, and highlight it in the transcript.
        In addition, please complete the <a href="https://davidrosenberg.github.io/mlcourse/Notes/prereq-questions/prereq-self-assessment.pdf">Prerequisite Questionnaire</a> for self-assessment.
        </p>
        <ul>
            <li><a href="https://github.com/briandalessandro/DataScienceCourse/blob/master/ipython/references/Syllabus_2017.pdf"><strong>DS-GA-1001: Intro to Data Science</strong></a> or its equivalent</li>
            <li><a href="http://www.cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/index.html"><strong>DS-GA-1002: Statistical and Mathematical Methods</strong></a> or its equivalent</li>
            <li><strong>Solid mathematical background</strong>, equivalent to a 1-semester undergraduate course in each of the following: linear algebra, multivariate calculus (primarily differential calculus), probability theory, and statistics.  (The coverage in the 2015 version of DS-GA 1002, linked above, is sufficient.)</li>
            <li><strong>Python programming required</strong> for most homework assignments.</li>
            <li><em>Recommended:</em> Computer science background up to a "data structures and algorithms" course</li>
            <li><em>Recommended:</em> At least one advanced, proof-based mathematics course</li>
            <li>Some prerequisites may be waived with permission of the instructor</li>
            <li>You can self-assess your preparation by filling out the <a href="https://davidrosenberg.github.io/mlcourse/Notes/prereq-questions/prereq-self-assessment.pdf">Prerequisite Questionnaire</a></li>
        </ul>
    </section>

    <section>
        <h1>Logistics</h1>
        <ul>
            <li><strong>Lecture format</strong>: In-person with Zoom recording </li>
            <li><strong>Lecture location</strong>: GCASL_C95 - Global Center for Academic & Spiritual Life, 238 Thompson Street, New York, NY, 10012-1020</li>
            <li><strong>Office hours</strong>:</li>
            <ul>
                <li>Mengye Ren: Tuesday 2:00PM - 3:00PM; Room 508 (60 5th Ave)
                <li>Ravid Shwartz-Ziv: Tuesday 9:00AM - 10:00AM; Room 205C (60 5th Ave)
                <li>Colin Wan: Mon 5:00PM - 6:00PM; Room 204 (60 5th Ave)</li>
                <li>Ying Wang: Wed 6:00PM - 7:00PM; Room 204 (60 5th Ave)</li>
                <li>Yanlai Yang: Wed 1:00PM - 2:00PM; Room 204 (60 5th Ave)</li>
            </ul>
            <li><strong>Discussions</strong>: We will use <a href="https://campuswire.com/c/G0F20206F/feed">Campuswire</a> for class discussion. Rather than emailing questions to the teaching staff, please post your questions on Campuswire, where they will be answered by the instructors, TAs, graders, and other students.  For questions that are not specific to the class, you are also encouraged to post to <a href="http://stackoverflow.com/">Stack Overflow</a> for programming questions and <a href="http://stats.stackexchange.com/">Cross Validated</a> for statistics and machine learning questions.  Please also post a link to these postings in Campuswire, so others in the class can answer the questions and benefit from the answers.</li>
        </ul>
    </section>

    <section>
        <h1>Grading</h1>
        <ul>
            <li><strong>Homework (40%).</strong>
                There are 7-8 homeworks.
                See <a href="#assignments">Assignments</a> section for details.
                Some homeworks may have optional problems. You should view the optional problems primarily as a way to engage with more material, if you have the time.
                They will be counted towards extra credit.
            </li>
            <li><strong>Exams: midterm (30%) + final (30%).</strong>
                Exam dates and formats TBD.
            </li>
            <li><strong>Extra credits (2%).</strong>
                You will be awarded with up to 2% extra credit if you answer other students' questions in a substantial and helpful way on Campuswire.
                Extra credits may bump up your grade up to half a grade (e.g. B to B+).
            </li>
        </ul>
    </section>

</section>

<section id="resources">
    <h1>Resources</h1>
    <section>
        <h1>Related courses</h1>
        <ul>
            <li><a href="https://nyu-ds1003.github.io/spring2022/#home">Spring 2022</a> offering of DS-GA-1003</li>
            <li><a href="https://bloomberg.github.io/foml/#home">Foundations of Maching Learning</a> from Bloomberg ML EDU by David S. Rosenberg (with videos)</li>
        </ul>
    </section>

    <section id="textbooks">
        <h1>Textbooks</h1>

        <a href="https://web.stanford.edu/~hastie/ElemStatLearn/"><img src="images/hastie-1x.png" srcset="images/hastie-1x.png 1x, images/hastie-2x.jpg 2x, images/hastie-3x.jpg 3x" alt="The cover of Elements of Statistical Learning"></a>

        <a href="http://www-bcf.usc.edu/~gareth/ISL/"><img src="images/james-1x.jpg" srcset="images/james-1x.jpg 1x, images/james-2x.jpg 2x, images/james-3x.jpg 3x" alt="The cover of An Introduction to Statistical Learning"></a>

        <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/"><img src="images/shalev-shwartz-original.jpg" alt="The cover of Understanding Machine Learning: From Theory to Algorithms"></a>

        <a href="http://a.co/77AlDxk"><img src="images/bishop-1x.jpg" srcset="images/bishop-1x.jpg 1x, images/bishop-2x.jpg 2x, images/bishop-3x.jpg 3x" alt="The cover of Pattern Recognition and Machine Learning"></a>

        <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage"><img src="images/barber-1x.jpg" srcset="images/barber-1x.jpg 1x, images/barber-2x.jpg 2x, images/barber-3x.jpg 3x" alt="The cover of Bayesian Reasoning and Machine Learning"></a>

        <dl>

            <dt><a href="http://statweb.stanford.edu/~hastie/ElemStatLearn/"><cite>The
            Elements of Statistical Learning</cite> (Hastie, Friedman, and Tibshirani)</a>
            <dd>This will be our main textbook for L1 and L2 regularization, trees, bagging, random forests, and boosting.  It's written by three statisticians who invented many of the techniques discussed. There's an easier version of this book that covers many of the same topics, described below. (Available for free as a PDF.)

            <dt><a href="http://www-bcf.usc.edu/~gareth/ISL/"><cite>An Introduction to Statistical Learning</cite> (James, Witten, Hastie, and Tibshirani)</a>
            <dd>This book is written by two of the same authors as The Elements of Statistical Learning. It's much less intense mathematically, and it's good for a lighter introduction to the topics. (Available for free as a PDF.)

    	    <dt><a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning"><cite>Understanding Machine Learning: From Theory to Algorithms</cite> (Shalev-Shwartz and Ben-David)</a>
    	    <dd>Covers a lot of theory that we don't go into, but it would be a good supplemental resource for a more theoretical course, such as Mohri's <a href="http://www.cs.nyu.edu/~mohri/ml17/">Foundations of Machine Learning</a> course. (Available for free as a PDF.)

              <dt><a href="http://a.co/77AlDxk"><cite>Pattern Recognition and Machine Learning</cite> (Christopher Bishop)</a>
    	    <dd>Our primary reference for probabilistic methods, including bayesian regression, latent variable models, and the EM algorithm.  It's highly recommended, but unfortunately not free online.

    	    <dt><a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage"><cite>Bayesian Reasoning and Machine Learning</cite> (David Barber)</a>
    	    <dd>A very nice resource for our topics in probabilistic modeling, and a possible substitute for the Bishop book.  Would serve as a good supplemental reference for a more advanced course in probabilistic modeling, such as <a href="https://inf16nyu.github.io/home/">DS-GA 1005: Inference and Representation</a> (Available for free as a PDF.)
        </dl>

        <dt><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/"><cite>Hands-On Machine Learning with Scikit-Learn and TensorFlow</cite> (Aurélien Géron)</a>
            <dd>This is a practical guide to machine learning that corresponds fairly well with the content and level of our course.  While most of our homework is about coding ML from scratch with numpy, this book makes heavy use of scikit-learn and TensorFlow. Comfort with the first two chapters of this book would be part of the ideal preparation for this course, and it will also be a handy reference for practical projects and work beyond this course, when you'll want to make use of existing ML packages, rather than rolling your own.</dd>

    	      <dt><a href="http://data-science-for-biz.com/"><cite>Data Science for Business</cite> (Provost and Fawcett)</a>
    	          <dd>Ideally, this would be everybody's first book on machine learning.  The intended audience is both the ML practitioner and the ML product manager.  It's full of important core concepts and practical wisdom.  The math is so minimal that it's perfect for reading on your phone, and I encourage you to read it in parallel to doing this class, especially if you haven't taken DS-GA 1001.</dd>
            </dt>


    </section>

    <section id="references">
        <h1>Other tutorials and references</h1>

        <ul>
            <li>A <a href="https://nyu-ds1003.github.io/mlcourse/references/references.pdf">note</a> that can help you navigate the references topics by topics.
            <li><a href="http://www.cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/notes.html">Carlos Fernandez-Granda's lecture notes</a> provide a comprehensive review of the prerequisite material in linear algebra, probability, statistics, and optimization.
    	    <li><a href="http://nbviewer.ipython.org/github/briandalessandro/DataScienceCourse/tree/master/ipython/">Brian Dalessandro's iPython notebooks</a> from <a href="https://github.com/briandalessandro/DataScienceCourse/blob/master/ipython/references/Syllabus_2017.pdf"><strong>DS-GA-1001: Intro to Data Science</strong></a>
            <li><a href="http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=3274">The Matrix Cookbook</a> has lots of facts and identities about matrices and certain probability distributions.
            <li><a href="http://cs229.stanford.edu/section/cs229-prob.pdf">Stanford CS229: "Review of Probability Theory"</a>
            <li><a href="http://cs229.stanford.edu/section/cs229-linalg.pdf">Stanford CS229: "Linear Algebra Review and Reference"</a>
            <li><a href="http://www.umiacs.umd.edu/~hal/courses/2013S_ML/math4ml.pdf">Math for Machine Learning</a> by Hal Daumé III
        </ul>
    </section>

    <section id="software">
        <h1>Software</h1>

        <ul>
            <li><a href="http://www.numpy.org/">NumPy</a> is "the fundamental package for scientific computing with Python." Our homework assignments will use NumPy arrays extensively.
            <li><a href="http://scikit-learn.org/stable/">scikit-learn</a> is a comprehensive machine learning toolkit for Python. We won't use this for most of the homework assignments, since we'll be coding things from scratch. However, you may want to run the scikit-learn version of the algorithms to check that your own outputs are correct. Also, studying the source code can be a good learning experience.
        </ul>
    </section>
</section>

<section id="lectures">
    <h1>Lectures</h1>

    <ul class="abbreviations">
        <li> (HTF) refers to Hastie, Tibshirani, and Friedman's book <a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/"><cite>The Elements of Statistical Learning</cite></a>
        <li> (SSBD) refers to Shalev-Shwartz and Ben-David's book <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html/"><cite>Understanding Machine Learning: From Theory to Algorithms</cite></a>
        <li> (JWHT) refers to James, Witten, Hastie, and Tibshirani's book <a href="http://www-bcf.usc.edu/~gareth/ISL"><cite>An Introduction to Statistical Learning</cite></a>
    </ul>

    <ul>
        <li> Future schedule is subject to change.
            <!--
        <li> Pre-recorded lecture videos are on <a href="https://stream.nyu.edu/channel/DS-GA.1003%2BMachine%2BLearning%2B%2528Spring%2B2021%2529/205637133">NYUStream</a>.
        <li> <a href="https://forms.gle/N69XcP9456M3pzpV6">Feedback form</a>.
            -->
    </ul>

        <section class="module" id="lecture-week-1">
            <h1>Week 1</h1>
    
            <table>
                <thead>
                    <tr>
                        <th></th>
                        <th>Topics</th>
                        <th>Materials</th>
                        <th>References</th>
                    </tr>
                </thead>
                    <tr>
                        <th class="label">
                            <h1>
                                Lecture (TL)
                                <span class="date">Jan 24</span>
                            </h1>
                        </th>
                        <td class="slides">
                            <h1 class="phone-only-block">Topics</h1>
                                <ul>
                                        <li><a href="https://nyu-ds1003.github.io/mlcourse/2023/lectures/lec01/01a.overview.pdf">Course logistics and overview</a></li>
    
                                        <li><a href="https://nyu-ds1003.github.io/mlcourse/2023/lectures/lec01/01b.intro-machine-learning.pdf">Introduction to machine learning</a></li>
    
                                        <li><a href="https://nyu-ds1003.github.io/mlcourse/2023/lectures/lec01/01c.intro-stat-learning-theory.pdf">Introduction to statistical learning theory</a></li>
                                </ul>
                        </td>
                        <td class="notes">
                            <h1 class="phone-only-block">Materials</h1>
                                <ul>
                                        <li><a href="https://davidrosenberg.github.io/mlcourse/Archive/2019/Notes/conditional-expectations.pdf">Conditional expectations</a></li>
                                </ul>
                        </td>
                        <td class="references">
                            <h1 class="phone-only-block">References</h1>
                                (None)
                        </td>
                    </tr>
            </table>
        </section>
</section>
<section id="assignments">
    <h1>Assignments</h1>

    <div class="policies">
        <p><strong>Late Policy:</strong> Homeworks are due at 11:59 PM EST on the date specified. You have <strong>seven late days</strong> in total which can be used throughout the semester without penalty. Once you run out of late days, each additional late day will incur a <strong>20% penalty</strong>. For example, if you submit an assignment 1 day late after using all your late days, a score of 90 will only be counted as 72. Note that the maximum late days per homework is <strong>two days</strong>, meaning that Gradescope will not accept submissions 48 hours after the due date. </p>

        <p><strong>Collaboration Policy:</strong> You may form study groups and discuss problems with your classmates. However, you must write up the homework solutions and the code from scratch, without referring to notes from your joint session.  In your solution to each problem, you must write down the names of any person with whom you discussed the problem—this will not affect your grade.</p>

        <p><strong>Submission:</strong> Homework should be submitted through <a href="https://gradescope.com">Gradescope</a>.  If you have not used Gradescope before, please watch this short video: <a href="https://gradescope.com/get_started">"For students: submitting homework."</a>  At the beginning of the semester, you will be added to the Gradescope class roster. This will give you access to the course page, and the assignment submission form. To submit assignments, you will need to:</p>
        <ol>
            <li> Upload a single PDF document containing all the math, code, plots, and exposition required for each problem.</li>
            <li> Where homework assignments are divided into sections, <strong>please begin each section on a new page</strong>.</li>
            <li> You will then select the appropriate page ranges for each homework problem, as described in the "submitting homework" video.</li>
        </ol>
        <p><strong>Feedback:</strong> Check <a href="https://gradescope.com">Gradescope</a> to get your scores on each individual problem, as well as comments on your answers.
        Regrading requests should be submitted on Gradescope.
        </p>
    </div>

    <!--     <section class="homework" id="assignment-homework-0">
        <div class="module">
            <div class="title">
                <h1>Homework 0</h1>
                <p>Typesetting your homework</p>
            </div>
            <p class="deadline"><strong>Due:</strong> January 1st, 11:59 PM EST</p>
            <div class="files">
                    <a href="." class="pdf icon">hw0.pdf</a>
                    <a href="." class="zip icon">hw0.zip</a>
            </div>
        </div>
    </section>
 -->
</section>

<section id="people">
    <h1>People</h1>

    <section class="multiple-people">
        <h1>Instructors</h1>

	<ul>
        <div class="person module instructor">
            <img src="images/people/mengye_ren.jpg" alt="A photo of Mengye Ren">
            <div class="info">
                <p class="name"><a href="https://mengyeren.com">Mengye Ren</a></p>
                <p class="email"><a href="mailto:mengye@cs.nyu.edu">mengye@cs.nyu.edu</a></p>
                <p class="bio">Mengye Ren is an Assistant Professor of Computer Science and Data Science at NYU. His research focuses on deep learning and computer vision. </p>
            </div>
        </div>
        <div class="person module instructor">
            <img src="images/people/ravid_shwartz-ziv.jpg" alt="A photo of Ravid Shwartz-Ziv">
            <div class="info">
                <p class="name"><a href="https://www.ravid-shwartz-ziv.com">Ravid Shwartz-Ziv</a></p>
                <p class="email"><a href="mailto:rs8020@nyu.edu">rs8020@nyu.edu</a></p>
                <p class="bio"> Ravid Shwartz-Ziv is a Faculty Fellow at NYU CDS. His research focuses on machine learning.</p>
            </div>
        </div>
	</ul>

    </section>

    <section>
        <h1>Section Leaders</h1>

	<ul>
        <div class="person module instructor">
            <img src="images/people/colin_wan.jpg" alt="A photo of Colin Wan">
            <div class="info">
                <p class="name"><a href="">Colin Wan</a></p>
		        <p class="email"><a href="mailto:colin.wan@nyu.edu">colin.wan@nyu.edu</a></p>
                <p class="bio">Colin is an NYU alumnus. He graduated from the CDS Master's program in 2022.</p>
            </div>
        </div>
        <div class="person module instructor">
            <img src="images/people/ying_wang.jpg" alt="A photo of Ying Wang">
            <div class="info">
                <p class="name"><a href="">Ying Wang </a></p>
                <p class="email"><a href="mailto:yw3076@nyu.edu">yw3076@nyu.edu</a></p>
                <p class="bio">Ying is a second-year Masters student in the Data Science program at NYU CDS.</p>
            </div>
        </div>
        <div class="person module instructor">
            <img src="images/people/yanlai_yang.jpg" alt="A photo of Vishakh Padmakumar">
            <div class="info">
                <p class="name"><a href="">Yanlai Yang </a></p>
        <p class="email"><a href="mailto:yy2694@nyu.edu">yy2694@nyu.edu</a></p>
                <p class="bio">Yanlai is a first-year PhD student in computer science at NYU Courant.</p>
            </div>
        </div>
	</ul>
    </section>

    <section>
            <h1>Graders</h1>
    <ul>
        <div class="person module instructor">
            <img src="images/people/xiaojing_fan.jpg" alt="A photo of Xiaojing Fan">
            <div class="info">
                <p class="name"><a href="">Xiaojing Fan </a></p>
        <p class="email"><a href="xf435@nyu.edu">xf435@nyu.edu</a></p>
                <p class="bio">Xiaojing is a second-year Masters student in the Data Science program at NYU CDS.</p>
            </div>
       </div>

        <div class="person module instructor">
            <img src="images/people/jimmy_li.jpg" alt="A photo of Junze Li">
            <div class="info">
                <p class="name"><a href="">Junze Li </a></p>
		<p class="email"><a href="jl11390@nyu.edu">jl11390@nyu.edu</a></p>
                <p class="bio">Junze is a second-year Masters student in the Data Science program at NYU CDS</p>
            </div>
        </div>

        <div class="person module instructor">
            <img src="images/people/richard-john_lin.jpg" alt="A photo of Richard-John Lin">
            <div class="info">
                <p class="name"><a href="">Richard-John Lin </a></p>
		<p class="email"><a href="ryl7673@nyu.edu">ryl7673@nyu.edu</a></p>
                <p class="bio">Richard is a second-year Masters student in the Data Science program at NYU CDS. </p>
            </div>
        </div>

        <div class="person module instructor">
            <img src="images/people/ying_wang.jpg" alt="A photo of Ying Wang">
            <div class="info">
                <p class="name"><a href="">Ying Wang </a></p>
        <p class="email"><a href="yw3076@nyu.edu">yw3076@nyu.edu</a></p>
                <p class="bio">Ying is a second-year Masters student in the Data Science program at NYU CDS.</p>
            </div>
        </div>

        <div class="person module instructor">
            <img src="images/people/jerry_xue.jpg" alt="A photo of Jerry Xue">
            <div class="info">
                <p class="name"><a href="">Jerry Xue </a></p>
		<p class="email"><a href="jx898@nyu.edu">jx898@nyu.edu</a></p>
                <p class="bio">Jerry Xue is a second-year Master student in the Data Science program at NYU CDS.</p>
            </div>
        </div>


        <div class="person module instructor">
            <img src="images/people/frances_yuan.jpg" alt="A photo of Frances Yuan">
            <div class="info">
                <p class="name"><a href="">Frances Yuan </a></p>
		<p class="email"><a href="fy576@nyu.edu">fy576@nyu.edu</a></p>
                <p class="bio">Frances is a second-year Masters student in the Data Science program at NYU CDS.</p>
        </div>
	</div>
    </ul>
    </section>
</section>

<!--
<footer>
    <p>This website is developed <a href="https://github.com/davidrosenberg/ml2019/">on GitHub</a>; feel free to <a href="https://github.com/davidrosenberg/ml2019/issues">report issues or send feature requests</a>.</p>
</footer>
-->

<script async defer src="scripts/navigation.js"></script>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                             m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-64247420-3', 'auto');
    ga('send', 'pageview');

</script>
